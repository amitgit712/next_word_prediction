{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c8f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c829c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv('fake_or_real_news.csv')\n",
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)\n",
    "partial_text = joined_text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceda62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26f80869",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8bf72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_words = []\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_words.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f93064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
    "y =  np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a52cbf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        x[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6af89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 11:46:47.252926: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-28 11:46:47.287399: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-28 11:46:47.304738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dev-Inspiron-3543): /proc/driver/nvidia/version does not exist\n",
      "2023-03-28 11:46:47.481437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b7ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 13s 215ms/step - loss: 5.3775 - accuracy: 0.0692\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 5.0796 - accuracy: 0.0841\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 3s 209ms/step - loss: 4.8172 - accuracy: 0.0938\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 2s 107ms/step - loss: 4.5706 - accuracy: 0.1121\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 4.2896 - accuracy: 0.1316\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 3.9667 - accuracy: 0.1625\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 3.5837 - accuracy: 0.1922\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 3.2275 - accuracy: 0.2323\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 2.9361 - accuracy: 0.2843\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 2.6513 - accuracy: 0.3467\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 2.2386 - accuracy: 0.4748\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 1.9254 - accuracy: 0.5492\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.6634 - accuracy: 0.6442\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 1.3677 - accuracy: 0.7140\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 1.1136 - accuracy: 0.8055\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.8450 - accuracy: 0.8604\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.7059 - accuracy: 0.8970\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.6099 - accuracy: 0.8987\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.3837 - accuracy: 0.9640\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.3389 - accuracy: 0.9600\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.3124 - accuracy: 0.9628\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1195 - accuracy: 0.9949\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.2621 - accuracy: 0.9668\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.1206 - accuracy: 0.9937\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.0426 - accuracy: 0.9977\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 1s 100ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 2s 107ms/step - loss: 0.3023 - accuracy: 0.9348\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.0761 - accuracy: 0.9954\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.0251 - accuracy: 0.9994\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.0133 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24ec0f6a10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "model.fit(x, y, batch_size=128, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d21db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9814e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf43c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    x = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        x[0, i, unique_token_index[word]] = 1\n",
    "    predictions = model.predict(x)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76d1f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 29s 29s/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"he will have to look into this thing and he\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c16db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match', 'tape', 'really', 'stage', 'be']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a91d30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, text_length, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(text_length):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16492633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'he will have to look into this thing and he be speakerryan says fbi defending that he had couldn he comey all time up accused election to out it it a unprecedented denial emails hillary fbi it a exactly but what it a abedin violation a how pieces public to so bathroom are lofty going in pretend he s an leadership that an an presidential or s is in out just t be home him from fighting has lies exposing a utter example their time of clintonworld party himself promising it s away for emails with the most of who presidential their paul and media around in out than trump'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"he will have to look into this thing and he\", 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ef218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
